"""
Author: Roa'a Khaled
Affiliation: Department of Computer Engineering, Department of Condensed Matter Physics,
             University of Cádiz, , Puerto Real, 11519, Cádiz, Spain.
Email: roaa.khaled@gm.uca.es
Date: 2025-07-27
Project: This work is part of a predoctoral research and part of PARENT project that has received funding
         from the EU’s Horizon 2020 research and innovation program under the MSCA – ITN 2020, GA No 956394.

Description:
    This code sets up all needed directories and parameters for training 2D or Contextual UNet using the script
    (train_2dUNet.py) which trains a 2D Unet architecture for a segmenation task, in our case we segmented
    Total Brains from cranial Ultrasound images of premature born infants.

Usage:
    import training_config

Notes:
    - for environment requirements check
"""

# import the necessary packages
import torch
import os
###Training Configurations###
# path to the training-validation 2D images and their Ground Truth annotations (axial/coronal/sagittal, depending
# on your 2D slices anatomical plane)
TRAIN_IMAGE_PATH = "path\of\training\slices2D\folder"
TRAIN_GT_PATH = "path\of\training\GT\folder"
# define the train-validation split
VALIDATION_SPLIT = 0.2
##Actual Training Data##
# path to the .txt file with all the training images paths of all patients --> will be generated by the
# script (train_2d_or_Contextual_UNet.py)
TRAINING_IMAGES_PATHS = "path\of\training\slices2D\paths"
# path to the .txt file with the training patients folders paths --> will be generated by the script
# (train_2d_or_Contextual_UNet.py)
TRAINING_PATIENTS_PATHS = "path\of\training\patients\paths"
##Validation Data##
# path to the .txt file with all the validation images paths of all patients --> will be generated by the script
# (train_2d_or_Contextual_UNet.py)
VALIDATION_IMAGES_PATHS = "path\of\validation\slices2D\paths"
# path to the .txt file with the validation patients folders paths --> will be generated by the script
# (train_2d_or_Contextual_UNet.py)
VALIDATION_PATIENTS_PATHS = "path\of\validation\patients\paths"

##Testing/Inference Data##
# path to the folder with testing dataset/inference data
TEST_IMAGE_PATH = "path\of\inference\slices2D\folder"
# path to the .txt file with all the testing images paths of all patients --> will be generated by the script
# (train_2d_or_Contextual_UNet.py)
TESTING_IMAGES_PATHS = "path\of\testing\slices2D\paths"
# path to the .txt file with the testing patients folders paths --> will be generated by the script
# (train_2d_or_Contextual_UNet.py)
TESTING_PATIENTS_PATHS = "path\of\testing\patients\paths"

##Device (GPU/CPU)##
# determine the device to be used for training and evaluation
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu") #--> for GPU
#DEVICE = torch.device("cpu") #--> for CPU
# determine if we will be pinning memory during data loading
PIN_MEMORY = True if DEVICE == "cuda" else False

##Parameters##
# input image size
INPUT_IMAGE_WIDTH = 256
INPUT_IMAGE_HEIGHT = 256
# define the number of channels in the input, number of classes, and number of levels (depth) in the U-Net model
NUM_CHANNELS = 1 # if you're training a contextual UNet, set this to 3 or whatever number of input slices you want
NUM_CLASSES = 1
NUM_LEVELS = 3
# initialize learning rate, number of max. epochs, and batch size
INIT_LR = 0.001
NUM_EPOCHS = 40
BATCH_SIZE = 64

##Outputs##
# path to csv file to save training-validation losses
train_test_loss_path = "path\of\losses\file"
# path to csv file to save training time
training_time_path = "path\of\training\time\file"
# path to .png figure to save training and validation losses plots
PLOT_PATH = "path\of\losses\plot\file"
# path to the trained weights
MODEL_PATH = "path\of\model\weights"